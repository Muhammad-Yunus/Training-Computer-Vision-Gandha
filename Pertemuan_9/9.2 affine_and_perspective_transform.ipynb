{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2 Geometric Transformations\n",
    "\n",
    "- 9.2.1 Affine Transform\n",
    "- 9.2.2 Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=\"forestgreen\">Affine Transformation</font> : \n",
    "    - <font color=\"orange\">Combination</font> of several geometric transformations like Translation, Rotation, Scaling, and Shearing.<br><br>\n",
    "    <img src=\"resource/affine_transformations.gif\" style=\"height:300px\"></img>\n",
    "    <img src=\"resource/affine_transformations_2.gif\" style=\"height:300px\"></img><br><br>\n",
    "- <font color=\"forestgreen\">Perspective Transformation</font> : \n",
    "    - <font color=\"orange\">Mapping</font> of points from one plane to another plane using <font color=\"orange\">homography matrix</font>.\n",
    "    - Used to <font color=\"orange\">correct perspective distortion</font> in images.<br><br>\n",
    "    <img src=\"resource/proj_rots.gif\" style=\"height:300px\"></img>\n",
    "    <img src=\"resource/projectives_2.gif\" style=\"height:300px\"></img><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ilustration of difference between Affine Transform and Perspective Transform : <br><br>\n",
    "<img src=\"resource/TransformationsDifference.png\" style=\"width:500px\"></img>\n",
    "\n",
    "<br><br><br>\n",
    "### 9.2.1 <font color=\"orange\">Affine Transform</font>\n",
    "- Affine Transform is a type of geometric transformation that <font color=\"orange\">preserves points, straight lines, and planes.</font>\n",
    "- In Affine Transform, <font color=\"orange\">parallel lines remain parallel after the transformation.</font>\n",
    "- Common types of Affine Transformations include Translation, Rotation, Scaling, and Shearing.<br><br>\n",
    "- To perform Affine Transform, we need to define a <font color=\"orange\">transformation matrix</font> `M`, a 2x3 matrix.\n",
    "- Transformation matrix `M` can be obtained using the function `cv2.getAffineTransform(pts1, pts2)`.\n",
    "- Where :\n",
    "    - `pts1` :  triangle vertices source image\n",
    "    - `pts2` :  triangle vertices destination image <br><br>\n",
    "- The transformation is applied using the function `cv2.warpAffine(src, M, dsize)`.\n",
    "- Where :\n",
    "    - `src` : source image\n",
    "    - `M` : transformation matrix\n",
    "    - `dsize` : size of output image <br><br>\n",
    "- Illustration of Affine Transform using 3 points mapping : <br><br>\n",
    "<img src=\"resource/Warp_Affine_Tutorial_Theory_0.jpg\" style=\"width:300px\"></img><br><br>\n",
    "- After affine transformation, <font color=\"orange\">the shape of the object may change</font>, but the <font color=\"orange\">lines remain straight and parallelism is preserved</font>. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## EXAMPLE 1 : Understanding Affine Transform\n",
    "- Choosing triangle vertices in source and destination images to see how the transformation works.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image `lena_border.jpg`\n",
    "img = cv2.imread('lena_border.jpg')\n",
    "\n",
    "# get image dimensions\n",
    "# height, width, channels\n",
    "h, w, c = img.shape\n",
    "\n",
    "\n",
    "# define triangle vertices in the input image\n",
    "# top-left, top-right, bottom-left\n",
    "pts1 = np.float32([[0, 0], [w-1, 0], [0, h-1]])\n",
    "\n",
    "# define triangle vertices in the output image with a `horizontal shearing effect`\n",
    "# top-left, top-right, bottom-left\n",
    "pts2 = np.float32([[0, 0], [w-1, 0], [int(0.2*w), h-1]])\n",
    "\n",
    "# get transformation matrix M\n",
    "M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "# apply warp affine\n",
    "result = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "\n",
    "# display results\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above example show how affine transform producing <font color=\"orange\">horizontal shearing effect</font> for destination triangle vertices defined as :\n",
    "    - top-left vertex : `(0, 0)`\n",
    "    - top-right vertex : `(w-1, 0)`\n",
    "    - bottom-left vertex : `(int(0.2*w), h-1)`\n",
    "- where `w` and `h` are width and height of the source image respectively.\n",
    "- `0.2*w` indicates that the <font color=\"orange\">bottom-left vertex is shifted 20% of the image width to the right</font>, creating a shearing effect.<br><br><br>\n",
    "- We can experiment with different combination of triangle vertices to see how the affine transformation affects the image.\n",
    "    - Try creating <font color=\"orange\">vertical shearing effect</font> by adjusting the y-coordinates of the top-right corner shifted by 20% of the image height to the top ( `0.2*h` ).<br><br>\n",
    "- Also, try to <font color=\"orange\">vertical and horizontal shearing effect at the same time</font> by adjusting both x and y coordinates of the bottom-left and top-right corners respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "### EXAMPLE 2 : Fixing Image Shearing Using Affine Transform\n",
    "- `book_sheared.jpg` : an image that has been sheared in y direction.\n",
    "- Goal : to correct the shearing effect using Affine Transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "- First, detect the contour of the object in the image to find the bounding box of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image `book_standing.jpg`\n",
    "img = cv2.imread('book_standing.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# convert to binary image using Otsu thresholding\n",
    "__, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # draw bounding rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# display image\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "- Then, find approximate minimum area rectangle to get the angle of the object using contour approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image `book_standing.jpg`\n",
    "img = cv2.imread('book_standing.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# convert to binary image using Otsu thresholding\n",
    "__, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "for cnt in contours :\n",
    "\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # find minimum enclosing object in clockwise direction \n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "\n",
    "    # iterate through each corner point and draw circle at each corner point\n",
    "    for point in approx : \n",
    "        cv2.circle(img, point[0], 10, (0, 0, 255), -1)\n",
    "        cv2.putText(img, f'{point[0][0]}, {point[0][1]}', point[0], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 1)\n",
    "        print(point[0])\n",
    "\n",
    "\n",
    "# display image\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "- Above code show how to find approximated corner points of book object in `book_sheared.jpg` image.<br><br>\n",
    "<img src=\"resource/approx-book.png\" style=\"width:300px\"></img><br><br>\n",
    "- We can identify ,\n",
    "    - 1st corner (top-right) -> `approx[0]`\n",
    "    - 2nd corner (top-left) -> `approx[1]`\n",
    "    - 3rd corner (bottom-left) -> `approx[2]`    \n",
    "    - 4th corner (bottom-right) -> `approx[3]`<br><br>\n",
    "- We will choose 3 corners from approximated rectangle on book object as triangle vertices in source image for affine transformation.\n",
    "- We can choose, <font color=\"orange\">top-left</font>, <font color=\"orange\">top-right</font>, and <font color=\"orange\">bottom-left</font> corners as triangle vertices in source image.<br><br>\n",
    "<img src=\"resource/Warp_Affine_Tutorial_Theory_1.jpg\" style=\"width:200px\"></img><br><br>\n",
    "- So `pts1` can be defined as :\n",
    "    - `pts1 = np.array([approx[1], approx[0], approx[2]], np.float32)`<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And finaly we can apply affine transformation to correct the shearing effect by defining `pts2` as the desired triangle vertices in destination image.\n",
    "- We can define `pts2` as : \n",
    "    - `pts2 = np.array([[0, 0], [w,0], [0, h]], np.float32)`\n",
    "- where `w` and `h` are width and height of the source image respectively.\n",
    "- The resulting image will have the <font color=\"orange\">shearing effect corrected</font>, making the book appear more rectangular and aligned properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image `book_standing.jpg`\n",
    "img = cv2.imread('book_standing.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# convert to binary image using Otsu thresholding\n",
    "__, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "\n",
    "    # find minimum enclosing object in clockwise direction \n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "    approx = approx[:,0,:] # extract points from array shape (4,1,2) to (4,2)\n",
    "                                                    \n",
    "\n",
    "    # construct pts1 which is the triangle vertices source image\n",
    "    # pts1 (top-left, top-right, bottom-left)\n",
    "    pts1 = np.array([approx[1], approx[0], approx[2]], np.float32)\n",
    "\n",
    "    # construct pts2 which is the triangle vertices destination image\n",
    "    # pts2 (top-left, top-right, bottom-left)\n",
    "    pts2 = np.array([[0, 0], [w,0], [0, h]], np.float32)\n",
    "\n",
    "    # get transformation matrix M\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "    # apply warp affine\n",
    "    result = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "\n",
    "# display results\n",
    "cv2.imshow('result', result)\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "____\n",
    "## 9.2.2 <font color=\"orange\">Perspective Transformation</font>\n",
    "\n",
    "- M is 3x3 transformation matrix for Perspective Transform.\n",
    "- to create M matrix, we need **4 points on the input image** and corresponding points on the **output image**\n",
    "- method `cv2.getPerspectiveTransform(pts1, pts2)`\n",
    "- where :\n",
    "    - `pts1` : four vertices source image\n",
    "    - `pts2` : four vertices destination image <br><br>\n",
    "<img src=\"resource/perspective.png\" style=\"width:400px\"></img> <br><br><br><br>\n",
    "### EXAMPLE 3 : Fixing Perspective Distortion in Sudoku Image : <br>\n",
    "<img src=\"resource/sudoku.png\" style=\"width:400px\"></img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start with detecting the largest contour in the image to find the Sudoku grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 'sudoku.jpg'\n",
    "img = cv2.imread('sudoku.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect edges using Canny edge detector\n",
    "edges_img = cv2.Canny(gray, 50, 150, gray)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter out small rects\n",
    "    if w < 50 or h < 50 :\n",
    "        continue\n",
    "\n",
    "    # draw bounding rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# display image\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('edges', edges_img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, find approximate polygon to get the corner points of the Sudoku grid using <font color=orange>contour approximation.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 'sudoku.jpg'\n",
    "img = cv2.imread('sudoku.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect edges using Canny edge detector\n",
    "edges_img = cv2.Canny(gray, 50, 150, gray)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter out small rects\n",
    "    if w < 50 or h < 50 :\n",
    "        continue\n",
    "    \n",
    "    # find minimum enclosing object in clockwise direction \n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "    \n",
    "    # iterate through each corner point and draw circle at each corner point\n",
    "    for point in approx : \n",
    "        cv2.circle(img, point[0], 10, (0, 0, 255), -1)\n",
    "        cv2.putText(img, f'{point[0][0]}, {point[0][1]}', point[0], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 1)\n",
    "        print(point[0])\n",
    "\n",
    "\n",
    "# display image\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('edges', edges_img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "- Above code show how to find approximated corner points of sudoku grid object in `sudoku.jpg` image.<br><br>\n",
    "<img src=\"resource/approx-sudoku.png\" style=\"width:700px\"></img><br><br>\n",
    "- We can identify ,\n",
    "    - 1st corner (top-right) -> `approx[0]`\n",
    "    - 2nd corner (top-left) -> `approx[1]`\n",
    "    - 3rd corner (bottom-left) -> `approx[2]`    \n",
    "    - 4th corner (bottom-right) -> `approx[3]`<br><br>\n",
    "- We will re-arrange point position from approximated rectangle on sudoku grid object as : \n",
    "    - top-left -> `approx[1]`\n",
    "    - bottom-left -> `approx[2]`\n",
    "    - bottom-right -> `approx[3]`\n",
    "    - top-right -> `approx[0]`\n",
    "    <br><br>\n",
    "- So `pts1` can be defined as :\n",
    "    - `pts1 = np.array([approx[1], approx[2], approx[3], approx[0]], np.float32)`<br><br><br><br>\n",
    "- And finaly we can apply perspective transformation to correct the perspective distortion by defining `pts2` as the desired corner points in destination image.\n",
    "- We can define `pts2` as :\n",
    "    - `pts2 = np.array([[0, 0], [0,h], [w, h], [w, 0]], np.float32)`\n",
    "    <br><br><br><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 'sudoku.jpg'\n",
    "img = cv2.imread('sudoku.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect edges using Canny edge detector\n",
    "edges_img = cv2.Canny(gray, 50, 150, gray)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter out small rects\n",
    "    if w < 50 or h < 50 :\n",
    "        continue\n",
    "    \n",
    "    # find minimum enclosing object in clockwise direction \n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "    approx = approx[:,0,:] # extract points from array shape (4,1,2) to (4,2)\n",
    "\n",
    "    \n",
    "    # define four vertices of source & destination image\n",
    "    # [top-left, bottom-right, bottom-left, top-right]\n",
    "    pts1 = np.array([approx[1], approx[2], approx[3], approx[0]], np.float32) # the corder of sudoku image\n",
    "    pts2 = np.float32([[0, 0], [0,h], [w, h], [w, 0]]) # target image corners\n",
    "\n",
    "\n",
    "    # create Perpective Transform Matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "    # Apply Warp perspective transform\n",
    "    output = cv2.warpPerspective(img, M, (w,h))\n",
    "\n",
    "\n",
    "\n",
    "# display result\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Perspective Transform Image\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "### EXAMPLE 4 : Correcting Perspective of License Plate Image : <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start with detecting the largest contour in the image to find the License Plate grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 'license_plate.jpg'\n",
    "img = cv2.imread('license_plate.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect edges using Canny edge detector\n",
    "edges_img = cv2.Canny(gray, 50, 150, gray)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter out small rects\n",
    "    if w < 50 or h < 50 :\n",
    "        continue\n",
    "    \n",
    "    # draw bounding rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# display image\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('edges', edges_img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, find approximate polygon to get the corner points of the Sudoku grid using <font color=orange>contour approximation.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 'license_plate.jpg'\n",
    "img = cv2.imread('license_plate.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect edges using Canny edge detector\n",
    "edges_img = cv2.Canny(gray, 50, 150, gray)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter out small rects\n",
    "    if w < 50 or h < 50 :\n",
    "        continue\n",
    "    \n",
    "    # find minimum enclosing object in clockwise direction \n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "    \n",
    "    # iterate through each corner point and draw circle at each corner point\n",
    "    for point in approx : \n",
    "        cv2.circle(img, point[0], 10, (0, 0, 255), -1)\n",
    "        cv2.putText(img, f'{point[0][0]}, {point[0][1]}', point[0], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 1)\n",
    "        cv2.drawContours(img, [approx], -1, (0,255,0), 2)\n",
    "        print(point[0])\n",
    "\n",
    "\n",
    "# display image\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('edges', edges_img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "#### ℹ️ <font color=cyan>Alternative Method to Find Corner Points of Object for Rounded Corner - Minimum Area Rectangle</font>\n",
    "- Above code show how to find approximated corner points of license plate object in `license_plate.jpg` image.<br><br>\n",
    "<img src=\"resource/approx-license-plate.png\" style=\"width:500px\"></img><br><br>\n",
    "\n",
    "\n",
    "- ⚠️⚠️⚠️ But, the <font color=orange>approximated point is not correcltly</font> at the corner of license plate object.\n",
    "- It's caused by the contour approximation is just <font color=orange>simplifies the contour based on curvature</font>.\n",
    "- When <font color=orange>edge of the object</font> is <font color=orange>not sharp enough</font> (rounded or beveled), the approximated point may not be exactly at the corner.\n",
    "<br><br><br><br>\n",
    "\n",
    "- To handle this case, we can use <font color=orange>minimum area rectangle</font> `cv2.minAreaRect()` to find the corner points of the object.\n",
    "- And use `cv2.boxPoints()` to get the corner points of the rectangle.\n",
    "- This method will give us more accurate corner points for objects with rounded edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 'license_plate.jpg'\n",
    "img = cv2.imread('license_plate.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect edges using Canny edge detector\n",
    "edges_img = cv2.Canny(gray, 50, 150, gray)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter out small rects\n",
    "    if w < 50 or h < 50 :\n",
    "        continue\n",
    "    \n",
    "    # find minimum enclosing object in clockwise direction\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = box.astype(int)\n",
    "\n",
    "    for point in box : \n",
    "        cv2.circle(img, point, 10, (0, 0, 255), -1)\n",
    "        cv2.putText(img, f'{point[0]}, {point[1]}', point, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 1)\n",
    "        cv2.drawContours(img, [box], -1, (0,255,0), 2)\n",
    "        print(point)\n",
    "\n",
    "\n",
    "# display image\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('edges', edges_img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "- Now we have the correct corner points of the license plate object.<br><br>\n",
    "<img src=\"resource/min-area-rect-license-plate.png\" style=\"width:500px\"></img><br><br>\n",
    "- We observe that the approximated corner points of license plate object are detected correctly.\n",
    "    - But the <font color=orange>point order is different</font> from what we found in sudoku grid example.\n",
    "    - 1st corner (bottom-left) -> `box[0]`\n",
    "    - 2nd corner (top-left) -> `box[1]`\n",
    "    - 3rd corner (top-right) -> `box[2]`    \n",
    "    - 4th corner (bottom-right) -> `box[3]`<br><br>\n",
    "- This situation can happen depending on the orientation of the object in the image.\n",
    "    - ⚠️⚠️⚠️ <font color=cyan>OpenCV will not guarantee the order of the points</font> returned by `cv2.minAreaRect()` or even contour approximation. \n",
    "    - So we <font color=orange>need to rearrange the points correctly</font> before applying perspective transformation.<br><br><br><br>\n",
    "\n",
    "- Now re-arrange the point into [top-left, bottom-left, bottom-right, top-right] define `pts1` as :\n",
    "    - `pts1 = np.array([box[1], box[0], box[3], box[2]], np.float32)`<br><br>\n",
    "- And finaly we can apply perspective transformation to correct the perspective distortion by defining `pts2` as the desired corner points in destination image.\n",
    "- We can define `pts2` as :\n",
    "    - `pts2 = np.array([[0, 0], [0,h], [w, h], [w, 0]], np.float32)`\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 'license_plate.jpg'\n",
    "img = cv2.imread('license_plate.jpg')\n",
    "\n",
    "# get image shape\n",
    "# h : height, w : width, c : channel\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect edges using Canny edge detector\n",
    "edges_img = cv2.Canny(gray, 50, 150, gray)\n",
    "\n",
    "# find contour, important to use cv2.CHAIN_APPROX_SIMPLE to only retrieve the corner points\n",
    "# corner points will be useful to construct transformation matrix in affine transform\n",
    "contours, __ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours :\n",
    "    # get bounding rect\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter out small rects\n",
    "    if w < 50 or h < 50 :\n",
    "        continue\n",
    "    \n",
    "    # find minimum enclosing object in clockwise direction\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = box.astype(int)\n",
    "\n",
    "    \n",
    "    # define four vertices of source & destination image\n",
    "    # [top-left, top-right, bottom-right, bottom-left]\n",
    "    pts1 = np.float32([box[1], box[0], box[3], box[2]]) # the corder of sudoku image\n",
    "    pts2 = np.float32([[0, 0], [0,h], [w, h], [w, 0]]) # target image corners\n",
    "\n",
    "\n",
    "    # create Perpective Transform Matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "    # Apply Warp perspective transform\n",
    "    output = cv2.warpPerspective(img, M, (w,h))\n",
    "\n",
    "\n",
    "\n",
    "# display result\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Perspective Transform Image\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BelajarOpenCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
